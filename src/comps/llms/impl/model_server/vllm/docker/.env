HF_TOKEN=<your-hf-api-key>

## VLLM Model Server Settings ##
HABANA_VISIBLE_DEVICES=all
LLM_VLLM_MODEL_NAME="Intel/neural-chat-7b-v3-3"
LLM_VLLM_PORT=8008
OMPI_MCA_btl_vader_single_copy_mechanism=none
PT_HPU_ENABLE_LAZY_COLLECTIVES=true
PT_HPU_LAZY_ACC_PAR_MODE=0
VLLM_CPU_KVCACHE_SPACE=40
VLLM_DTYPE=bfloat16
VLLM_MAX_NUM_SEQS=128
VLLM_SKIP_WARMUP=true
VLLM_TP_SIZE=1

## Proxy settings ##
#NO_PROXY=<your-no-proxy>
#HTTP_PROXY=<your-http-proxy>
#HTTPS_PROXY=<your-https-proxy>

